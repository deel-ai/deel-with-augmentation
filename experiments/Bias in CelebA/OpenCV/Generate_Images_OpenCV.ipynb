{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import Image as PilImage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HairSegmenter(img, dilate):\n",
    "    model_path = '/home/vuong.nguyen/vuong/augmentare/Bias Celeba/hair_segmenter.tflite'\n",
    "    base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "\n",
    "    BaseOptions = mp.tasks.BaseOptions\n",
    "    ImageSegmenter = mp.tasks.vision.ImageSegmenter\n",
    "    ImageSegmenterOptions = mp.tasks.vision.ImageSegmenterOptions\n",
    "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "    # Create a image segmenter instance with the image mode:\n",
    "    options = ImageSegmenterOptions(\n",
    "        base_options=BaseOptions(model_asset_path=model_path),\n",
    "        running_mode=VisionRunningMode.IMAGE,\n",
    "        output_category_mask=True)\n",
    "\n",
    "    BG_COLOR = (0, 0, 0) # gray\n",
    "    MASK_COLOR = (255, 255, 255) # white\n",
    "\n",
    "    with ImageSegmenter.create_from_options(options) as segmenter:\n",
    "        # Perform image segmentation on the provided single image.\n",
    "        # The image segmenter must be created with the image mode.\n",
    "        segmented_masks = segmenter.segment(img)\n",
    "        category_mask = segmented_masks.category_mask\n",
    "\n",
    "        # Generate solid color images for showing the output segmentation mask.\n",
    "        image_data = img.numpy_view()\n",
    "        fg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
    "        fg_image[:] = MASK_COLOR\n",
    "        bg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
    "        bg_image[:] = BG_COLOR\n",
    "\n",
    "        condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.2\n",
    "        output_image = np.where(condition, fg_image, bg_image)\n",
    "        mask = cv2.inRange(output_image, MASK_COLOR, MASK_COLOR)\n",
    "        mask = np.clip(mask, 0, 1)\n",
    "\n",
    "        kernel = np.ones((dilate, dilate), np.uint8)\n",
    "        dilated_mask = cv2.dilate(mask, kernel)\n",
    "    return mask, dilated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_opencv(path_source, path_target, color_filter, alpha):\n",
    "    files_list = sorted(os.listdir(path_source))\n",
    "    for curr_file in files_list:\n",
    "        face = cv2.imread(f\"{path_source}/{curr_file}\")\n",
    "        image = mp.Image.create_from_file(f\"{path_source}/{curr_file}\")\n",
    "        mask, _ = HairSegmenter(image, 5)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "        _, mask = cv2.threshold(mask, thresh=180, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "        hair_color = np.copy(face)\n",
    "        # boolean indexing and assignment based on mask\n",
    "        hair_color[(mask==255).all(-1)] = color_filter\n",
    "        hair_color_w = cv2.addWeighted(hair_color, 1-alpha, face, alpha, 0)\n",
    "        #hair_color_w = cv2.cvtColor(hair_color_w, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(f\"{path_target}/new_{curr_file}\", hair_color_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_data(path_target, label, sens):\n",
    "    files_list = sorted(os.listdir(path_target))\n",
    "    elements = []\n",
    "    for curr_file in files_list:\n",
    "        elements.append((curr_file, label, sens))\n",
    "    df = pd.DataFrame(elements, columns=[\"image_id\", \"Male\", \"Sens\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_source = \"/home/vuong.nguyen/vuong/augmentare/Bias Celeba/dataset_gan/Classic/female_blond\"\n",
    "path_target = \"/home/vuong.nguyen/vuong/augmentare/Bias Celeba/new_dataset/Classic/female_gray\"\n",
    "color_filter = [91,91,91]\n",
    "alpha = 0.408\n",
    "get_data_opencv(path_source, path_target, color_filter, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_target = \"/home/vuong.nguyen/vuong/augmentare/Bias Celeba/new_dataset/Classic/male_blond\"\n",
    "df = get_df_data(path_target, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/vuong.nguyen/vuong/augmentare/Bias Celeba/new_dataset/Classic/new_male_blond.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, path_source, path_target):\n",
    "    if len(df) < 1000:\n",
    "        num = len(df)\n",
    "    else:\n",
    "        num = 1000\n",
    "\n",
    "    #files_list = sorted(os.listdir(path_source))\n",
    "    file_names = df[\"image_id\"].sample(num).tolist()\n",
    "    #file_names = files[:num]\n",
    "\n",
    "    for curr_file in file_names:\n",
    "        shutil.copy(os.path.join(path_source, curr_file), os.path.join(path_target, curr_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male_gray = pd.read_csv(\"/home/vuong.nguyen/vuong/augmentare/Bias Celeba/dataframe_dataset/df_male_gray.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data(\n",
    "    df = df_male_gray,\n",
    "    path_source='dataset/img_align_celeba/img_align_celeba',\n",
    "    path_target='dataset_gan/male_gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
